{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Apartments\n",
    "\n",
    "## General Approach\n",
    "\n",
    "If not all data is in tables, we can use web scraping to extract the data from the website. In this notebook, we will scrape the data from the website of a general marketplace ss.com . We will extract the data and store it in a pandas DataFrame.\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. We will use the requests library to get the HTML code of the website.\n",
    "2. We will use the BeautifulSoup library to parse the HTML code.\n",
    "3. We will extract the data from the HTML code. We will use BeautifulSoup to find the data we need.\n",
    "4. We will store the data in a pandas DataFrame.\n",
    "5. We will clean the data. - optionally\n",
    "6. We will save the data in a CSV or XLSX or JSON file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "# first we load libraries\n",
    "# let's start with standard libraries\n",
    "# we will use time to pause between requests - good practice\n",
    "import time\n",
    "# we will use datetime to get the current date and time for custom file names\n",
    "from datetime import datetime\n",
    "\n",
    "# we will need requests to get the data from the web\n",
    "import requests\n",
    "\n",
    "# we will want BeautifulSoup to parse the data\n",
    "from bs4 import BeautifulSoup\n",
    "# if you dot have BeautifulSoup installed, you can install it with pip install beautifulsoup4\n",
    "# official BeautifulSoup documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "# in our case pip install pandas[html] will install BeautifulSoup as well\t\n",
    "\n",
    "# we will need pandas to manipulate the data - once we have it\n",
    "import pandas as pd\n",
    "# pandas version\n",
    "print(f\"pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will open the following url: https://www.ss.com/lv/real-estate/flats/riga/centre/sell/\n"
     ]
    }
   ],
   "source": [
    "# now we just need a url to scrape\n",
    "url = \"https://www.ss.com/lv/real-estate/flats/riga/centre/sell/\"\n",
    "print(f\"Will open the following url: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page https://www.ss.com/lv/real-estate/flats/riga/centre/sell/ loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# now we will request the data from the web\n",
    "response = requests.get(url)\n",
    "# check response and raise error if it is not 200\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f\"Failed to load page, status code: {response.status_code}\")\n",
    "else:\n",
    "    print(f\"Page {url} loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<HTML lang=\"lv\"><HEAD>\n",
      "<title>SS.COM Dzīvokļi - Rīga - Centrs, Cenas, Pārdod - Slu\n"
     ]
    }
   ],
   "source": [
    "# now we have ALL the data for the page in our memory\n",
    "# let's look at first 100 characters of text\n",
    "print(response.text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valdemāra is mentioned at position 17057\n",
      "</option><option value=\"4545\">Valdemāra</option><option valu\n"
     ]
    }
   ],
   "source": [
    "# we could parse our html by hand but it would be quite painful and unnecessary\n",
    "# for example I could find where Valdemāra is mentioned\n",
    "valdemara = response.text.find(\"Valdemāra\")\n",
    "print(f\"Valdemāra is mentioned at position {valdemara}\")\n",
    "# i could print some 60 characters around it\n",
    "print(response.text[valdemara-30:valdemara+30])\n",
    "# so it is possible but too slow and error prone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making soup out of HTML\n",
    "\n",
    "Instead we will BeautifulSoup library to parse the HTML code. We will extract the data from the HTML code. We will use BeautifulSoup to find the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>SS.COM Dzīvokļi - Rīga - Centrs, Cenas, Pārdod - Sludinājumi</title>\n"
     ]
    }
   ],
   "source": [
    "# so we will make soup out of response\n",
    "soup = BeautifulSoup(response.text, 'lxml') # we do not have to specify parser \n",
    "#but lxml is considered better than default html.parser\n",
    "# if you do not have lxml installed, you can install it with pip install lxml\n",
    "# alternatively you could just use the default parser\n",
    "# soup = BeautifulSoup(response.text)\n",
    "# print title of page\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr id=\"head_line\">\n",
      "<td class=\"msg_column\" colspan=\"3\" width=\"70%\">\n",
      "<span style=\"float:left;\"> Sludinājumi\n",
      "</span>\n",
      "<span align=\"right\" class=\"msg_column\" style=\"float:right;text-align:right;padding-right:3px;\">\n",
      "<noindex>\n",
      "<a class=\"a19\" href=\"/lv/real-estate/flats/riga/centre/sell/fDgSeF4S.html\" rel=\"nofollow\">datums</a></noindex></span>\n",
      "</td>\n",
      "<td class=\"msg_column_td\" nowrap=\"\"><noindex><a class=\"a18\" href=\"/lv/real-estate/flats/riga/centre/sell/fDgSeF4SFDwT.html\" rel=\"nofollow\" title=\"\">Iela</a></noindex></td><td class=\"msg_column_td\" nowrap=\"\"><noindex><a class=\"a18\" href=\"/lv/real-estate/flats/riga/centre/sell/fDgSeF4SelM=.html\" rel=\"nofollow\" title=\"\">Ist.</a></noindex></td><td class=\"msg_column_td\" nowrap=\"\"><noindex><a class=\"a18\" href=\"/lv/real-estate/flats/riga/centre/sell/fDgSeF4QelM=.html\" rel=\"nofollow\" title=\"\">m2</a></noindex></td><td class=\"msg_column_td\" nowrap=\"\"><noindex><a class=\"a18\" href=\"/lv/real-estate/flats/riga/centre/sell/fDgSeF4XelM=.html\" rel=\"nofollow\" title=\"\">Stāvs</a></noindex></td><td class=\"msg_column_td\" nowrap=\"\"><noindex><a class=\"a18\" href=\"/lv/real-estate/flats/riga/centre/sell/fDgSeF4VelM=.html\" rel=\"nofollow\" title=\"\">Sērija</a></noindex></td><td background=\"https://i.ss.com/img/pl.gif\" class=\"msg_column\" nowrap=\"\" style=\"border-left:1px #FFFFFF solid;\"><noindex><a class=\"a18\" href=\"/lv/real-estate/flats/riga/centre/sell/fDgSeF4bRDwT.html\" rel=\"nofollow\">Cena, m2</a></noindex></td><td class=\"msg_column_td\" nowrap=\"\"><noindex><a class=\"a18\" href=\"/lv/real-estate/flats/riga/centre/sell/fDgSeF4belM=.html\" rel=\"nofollow\" title=\"\">Cena</a></noindex></td></tr>\n"
     ]
    }
   ],
   "source": [
    "# let's get a table row headline\n",
    "# notice that tr element has an id of head_line\n",
    "# id attributes are supposed to be unique\n",
    "# we can use this to find our row\n",
    "headline_row = soup.find(\"tr\", {\"id\": \"head_line\"})\n",
    "# so we passed two arguments to find\n",
    "# first is the name of the tag we are looking for  \n",
    "# second is a dictionary of attributes we are looking for\n",
    "print(headline_row)\n",
    "# in this case I bypassed the need to look for specific table since I alread know the id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 table data elements\n",
      "[<td background=\"https://i.ss.com/img/pl.gif\" class=\"msg_column\" nowrap=\"\" style=\"border-left:1px #FFFFFF solid;\"><noindex><a class=\"a18\" href=\"/lv/real-estate/flats/riga/centre/sell/fDgSeF4bRDwT.html\" rel=\"nofollow\">Cena, m2</a></noindex></td>, <td class=\"msg_column_td\" nowrap=\"\"><noindex><a class=\"a18\" href=\"/lv/real-estate/flats/riga/centre/sell/fDgSeF4belM=.html\" rel=\"nofollow\" title=\"\">Cena</a></noindex></td>]\n"
     ]
    }
   ],
   "source": [
    "# now we could find all td - table data elements in the row\n",
    "# td docs: https://developer.mozilla.org/en-US/docs/Web/HTML/Element/td\n",
    "table_data = headline_row.find_all(\"td\")\n",
    "# how many\n",
    "print(f\"Found {len(table_data)} table data elements\")\n",
    "# print last two\n",
    "print(table_data[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sludinājumi\\r\\n\\n\\n\\ndatums', 'Iela', 'Ist.', 'm2', 'Stāvs', 'Sērija', 'Cena, m2', 'Cena']\n"
     ]
    }
   ],
   "source": [
    "# now let's extract all text from each td\n",
    "# we can use simple list comprehension\n",
    "# table_data_text = [td.text for td in table_data]\n",
    "# again we could have done this with for loop\n",
    "table_data_text = []\n",
    "for td in table_data:\n",
    "    table_data_text.append(td.text.strip())\n",
    "print(table_data_text)\n",
    "# well the first element is kind of useless we would want the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('URL', 'Description', 'Iela', 'Ist.', 'm2', 'Stāvs', 'Sērija', 'Cena, m2', 'Cena')\n"
     ]
    }
   ],
   "source": [
    "# let's write a function that will get soup as parameter and return a list of column names\n",
    "# also we will provide three more parameters\n",
    "# id to use to find the row\n",
    "# how many columns to skip\n",
    "# and a tuple of column names to start with\n",
    "def get_column_names(soup, id=\"head_line\", skip=1, start=(\"URL\", \"Description\")):\n",
    "    # find the row\n",
    "    headline_row = soup.find(\"tr\", {\"id\": id})\n",
    "    # check that we found the row\n",
    "    if headline_row is None:\n",
    "        raise Exception(f\"Failed to find row with id: {id}\")\n",
    "    # find all table data elements\n",
    "    table_data = headline_row.find_all(\"td\")\n",
    "    # extract text\n",
    "    table_data_text = [td.text.strip() for td in table_data]\n",
    "    # return the list of column names\n",
    "    return start + tuple(table_data_text[skip:]) # we could have made start list and then used start.extend(table_data_text[skip:])\n",
    "\n",
    "# let's test our function on our soup\n",
    "column_names = get_column_names(soup)\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39 rows\n"
     ]
    }
   ],
   "source": [
    "# now we want to gather all table rows that have id that starts with tr_\n",
    "# first we get all table rows\n",
    "all_rows = soup.find_all(\"tr\")\n",
    "# how many\n",
    "print(f\"Found {len(all_rows)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 apartment rows\n"
     ]
    }
   ],
   "source": [
    "# now let's filter those rows that have id starting with tr_\n",
    "# lets start with loop solution\n",
    "apartment_rows = []\n",
    "for row in all_rows:\n",
    "    if row.get(\"id\", \"\").startswith(\"tr_\"):\n",
    "    # id attribute is not guaranteed\n",
    "    # so get is better than direct access\n",
    "    # then we can always use startswith method\n",
    "        # we will add one more check\n",
    "        # we only want those rows that do not start with tr_bnr\n",
    "        # those are banners and we are not interested in them\n",
    "        if not row.get(\"id\", \"\").startswith(\"tr_bnr\"):\n",
    "            apartment_rows.append(row)\n",
    "# how many\n",
    "print(f\"Found {len(apartment_rows)} apartment rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr id=\"tr_55022175\"><td class=\"msga2 pp0\"><input id=\"c55022175\" name=\"mid[]\" type=\"checkbox\" value=\"55022175_1106_0\"/></td><td class=\"msga2\"><a href=\"/msg/lv/real-estate/flats/riga/centre/bcmghe.html\" id=\"im55022175\"><img alt=\"\" class=\"isfoto foto_list\" src=\"https://i.ss.com/gallery/7/1231/307705/61540873.th2.jpg\"/></a></td><td class=\"msg2\"><div class=\"d1\"><a class=\"am\" data=\"ZCU5QSU5NyU4RSU3RSVBQXolQUVqaiU5NyU5QyU4OSU3RCVBRndjbWolOUIlOUUlODV3JUE4c2I=|3ffUFxC29\" href=\"/msg/lv/real-estate/flats/riga/centre/bcmghe.html\" id=\"dm_55022175\">Plašas telpas jūsu plāniem. Ideāli gan sev, gan kā Invest projek</a></div></td><td c=\"1\" class=\"msga2-o pp6\" nowrap=\"\">Dzirnavu 157</td><td c=\"1\" class=\"msga2-o pp6\" nowrap=\"\">4</td><td c=\"1\" class=\"msga2-o pp6\" nowrap=\"\">68</td><td c=\"1\" class=\"msga2-o pp6\" nowrap=\"\">1/3</td><td c=\"1\" class=\"msga2-o pp6\" nowrap=\"\">P. kara</td><td c=\"1\" class=\"msga2-o pp6\" nowrap=\"\">372 €</td><td c=\"1\" class=\"msga2-o pp6\" nowrap=\"\">25,300  €</td></tr>\n"
     ]
    }
   ],
   "source": [
    "# let's analyze the first row\n",
    "first_row = apartment_rows[0]\n",
    "# print first row\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Plašas telpas jūsu plāniem. Ideāli gan sev, gan kā Invest projek\n",
      "Dzirnavu 157\n",
      "4\n",
      "68\n",
      "1/3\n",
      "P. kara\n",
      "372 €\n",
      "25,300  €\n"
     ]
    }
   ],
   "source": [
    "# let us extract text from all td elements\n",
    "# we will use list comprehension\n",
    "first_row_data = [td.text.strip() for td in first_row.find_all(\"td\")]\n",
    "# print first row data\n",
    "print(*first_row_data, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/msg/lv/real-estate/flats/riga/centre/bcmghe.html\n"
     ]
    }
   ],
   "source": [
    "# so first cell is not needed at all we can skip that\n",
    "# second cell contains anchor link which we could use to make a url to the ad\n",
    "# third cell contains the description and so on\n",
    "\n",
    "# let's get url from the second cell\n",
    "# we will use find method to find the first anchor tag\n",
    "# then we will get the href attribute\n",
    "# we will use get method to get the attribute\n",
    "\n",
    "# first we get the second cell\n",
    "second_cell = first_row.find_all(\"td\")[1]\n",
    "# then we get the anchor tag\n",
    "anchor = second_cell.find(\"a\")\n",
    "# then we get the href attribute\n",
    "url = anchor.get(\"href\") # anchor would always have href attribute\n",
    "# print url\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ss.com/msg/lv/real-estate/flats/riga/centre/bcmghe.html\n"
     ]
    }
   ],
   "source": [
    "# we just need a prefix to make it a full url\n",
    "prefix = \"https://www.ss.com\"\n",
    "full_url = prefix + url\n",
    "print(full_url)\n",
    "# so this is the info we could not extract with pandas table reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can make a function to extract all data from a row\n",
    "# we will row and column names as parameters\n",
    "# we will return a dictionary - \n",
    "# why? because list of dictionaries converts nicely to Pandas DataFrame\n",
    "def get_ad_dict(row, column_names, url_td=1, prefix=\"https://www.ss.com\"):\n",
    "    # first we get all table data elements\n",
    "    table_data = row.find_all(\"td\")\n",
    "    # now we find url from index with url_td\n",
    "    # typically it will be second element with index 1\n",
    "    url = prefix + table_data[url_td].find(\"a\").get(\"href\")\n",
    "    # then we extract text from each element after url_td\n",
    "    table_data_text = [td.text.strip() for td in table_data[url_td+1:]]\n",
    "    # add url to beginning of the list\n",
    "    table_data_text.insert(0, url)\n",
    "    # then we make a dictionary from column names and row data\n",
    "    # assert column names and table data text have the same length\n",
    "    assert len(column_names) == len(table_data_text) \n",
    "    # above not required but to catch some errors\n",
    "    return dict(zip(column_names, table_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'URL': 'https://www.ss.com/msg/lv/real-estate/flats/riga/centre/bcmghe.html', 'Description': 'Plašas telpas jūsu plāniem. Ideāli gan sev, gan kā Invest projek', 'Iela': 'Dzirnavu 157', 'Ist.': '4', 'm2': '68', 'Stāvs': '1/3', 'Sērija': 'P. kara', 'Cena, m2': '372 €', 'Cena': '25,300  €'}\n"
     ]
    }
   ],
   "source": [
    "# now let us test our function\n",
    "first_ad_dict = get_ad_dict(first_row, column_names)\n",
    "print(first_ad_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 ads\n",
      "{'URL': 'https://www.ss.com/msg/lv/real-estate/flats/riga/centre/bcmghe.html', 'Description': 'Plašas telpas jūsu plāniem. Ideāli gan sev, gan kā Invest projek', 'Iela': 'Dzirnavu 157', 'Ist.': '4', 'm2': '68', 'Stāvs': '1/3', 'Sērija': 'P. kara', 'Cena, m2': '372 €', 'Cena': '25,300  €'}\n",
      "{'URL': 'https://www.ss.com/msg/lv/real-estate/flats/riga/centre/dbhnb.html', 'Description': 'Mūsdienīgs dzīvoklis centrā, atjaunotā namā, kas renovēts cienot', 'Iela': 'Cēsu 5', 'Ist.': '3', 'm2': '72', 'Stāvs': '2/5', 'Sērija': 'P. kara', 'Cena, m2': '2,569 €', 'Cena': '185,000  €'}\n",
      "{'URL': 'https://www.ss.com/msg/lv/real-estate/flats/riga/centre/adoki.html', 'Description': 'Omulīgs dzīvoklis ar labu mājas sajūtu, 2 istabas, 35 kv. m, 2/5', 'Iela': 'Antonijas 15', 'Ist.': '2', 'm2': '35', 'Stāvs': '2/5', 'Sērija': 'P. kara', 'Cena, m2': '2,143 €', 'Cena': '75,000  €'}\n"
     ]
    }
   ],
   "source": [
    "# now we can make a function that will create a list of dictionaries from all rows\n",
    "# we pass in all_rows and get a list of dictionaries\n",
    "def get_all_ads(all_rows, column_names):\n",
    "    # we will use list comprehension\n",
    "    return [get_ad_dict(row, column_names) for row in all_rows]\n",
    "\n",
    "# let's test our function\n",
    "all_ads = get_all_ads(apartment_rows, column_names)\n",
    "# how many\n",
    "print(f\"Found {len(all_ads)} ads\")\n",
    "# let's print first 3 ads\n",
    "for ad in all_ads[:3]:\n",
    "    print(ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Iela</th>\n",
       "      <th>Ist.</th>\n",
       "      <th>m2</th>\n",
       "      <th>Stāvs</th>\n",
       "      <th>Sērija</th>\n",
       "      <th>Cena, m2</th>\n",
       "      <th>Cena</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ss.com/msg/lv/real-estate/flats/ri...</td>\n",
       "      <td>Plašas telpas jūsu plāniem. Ideāli gan sev, ga...</td>\n",
       "      <td>Dzirnavu 157</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>1/3</td>\n",
       "      <td>P. kara</td>\n",
       "      <td>372 €</td>\n",
       "      <td>25,300  €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ss.com/msg/lv/real-estate/flats/ri...</td>\n",
       "      <td>Mūsdienīgs dzīvoklis centrā, atjaunotā namā, k...</td>\n",
       "      <td>Cēsu 5</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>2/5</td>\n",
       "      <td>P. kara</td>\n",
       "      <td>2,569 €</td>\n",
       "      <td>185,000  €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ss.com/msg/lv/real-estate/flats/ri...</td>\n",
       "      <td>Omulīgs dzīvoklis ar labu mājas sajūtu, 2 ista...</td>\n",
       "      <td>Antonijas 15</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>2/5</td>\n",
       "      <td>P. kara</td>\n",
       "      <td>2,143 €</td>\n",
       "      <td>75,000  €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ss.com/msg/lv/real-estate/flats/ri...</td>\n",
       "      <td>Renovētā mājā pārdod gaišu, klusu 4 istabu dzī...</td>\n",
       "      <td>Čaka 31</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>3/4</td>\n",
       "      <td>P. kara</td>\n",
       "      <td>1,959 €</td>\n",
       "      <td>145,000  €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ss.com/msg/lv/real-estate/flats/ri...</td>\n",
       "      <td>Renovētā mājā pārdod gaišu, klusu 3 istabu Dzī...</td>\n",
       "      <td>Čaka 31</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>3/4</td>\n",
       "      <td>P. kara</td>\n",
       "      <td>1,452 €</td>\n",
       "      <td>122,000  €</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://www.ss.com/msg/lv/real-estate/flats/ri...   \n",
       "1  https://www.ss.com/msg/lv/real-estate/flats/ri...   \n",
       "2  https://www.ss.com/msg/lv/real-estate/flats/ri...   \n",
       "3  https://www.ss.com/msg/lv/real-estate/flats/ri...   \n",
       "4  https://www.ss.com/msg/lv/real-estate/flats/ri...   \n",
       "\n",
       "                                         Description          Iela Ist.  m2  \\\n",
       "0  Plašas telpas jūsu plāniem. Ideāli gan sev, ga...  Dzirnavu 157    4  68   \n",
       "1  Mūsdienīgs dzīvoklis centrā, atjaunotā namā, k...        Cēsu 5    3  72   \n",
       "2  Omulīgs dzīvoklis ar labu mājas sajūtu, 2 ista...  Antonijas 15    2  35   \n",
       "3  Renovētā mājā pārdod gaišu, klusu 4 istabu dzī...       Čaka 31    4  74   \n",
       "4  Renovētā mājā pārdod gaišu, klusu 3 istabu Dzī...       Čaka 31    3  84   \n",
       "\n",
       "  Stāvs   Sērija Cena, m2        Cena  \n",
       "0   1/3  P. kara    372 €   25,300  €  \n",
       "1   2/5  P. kara  2,569 €  185,000  €  \n",
       "2   2/5  P. kara  2,143 €   75,000  €  \n",
       "3   3/4  P. kara  1,959 €  145,000  €  \n",
       "4   3/4  P. kara  1,452 €  122,000  €  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I can convert all_ads into DataFrame\n",
    "all_ads_df = pd.DataFrame(all_ads)\n",
    "# let's check the first few rows\n",
    "all_ads_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
